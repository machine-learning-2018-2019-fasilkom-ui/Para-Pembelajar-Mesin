{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO IMPROVEMENT : stemming, normalisasi untuk naive bayes\n",
    "# Korpus belum lengkap,masih minim\n",
    "# perhitungan predict class dengan naive bayes\n",
    "dataset = open('korpus.txt', 'r')\n",
    "\n",
    "words = dataset.read().split()\n",
    "\n",
    "#gabung bahasa indonesia/inggris\n",
    "stopwords = [\"in\", \"a\", \"book\", \"write\", \"writer\",\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "rekam_judul = False\n",
    "rekam_sinopsis = False\n",
    "rekam_fakultas = False\n",
    "\n",
    "tmp_judul = []\n",
    "tmp_sinopsis = []\n",
    "tmp_fakultas = []\n",
    "\n",
    "\n",
    "kata_judul = {}\n",
    "kata_sinopsis = {}\n",
    "for i in words:\n",
    "    if(i == '<JUDUL>'):\n",
    "        rekam_judul = True\n",
    "    elif(i == '</JUDUL>'):\n",
    "        rekam_judul = False\n",
    "    elif(i == '<SINOPSIS>'):\n",
    "        rekam_sinopsis = True\n",
    "    elif(i == '</SINOPSIS>'):\n",
    "        rekam_sinopsis = False\n",
    "    elif(i == '<FAKULTAS>'):\n",
    "        rekam_fakultas = True\n",
    "    elif(i == '</FAKULTAS>'):\n",
    "        rekam_fakultas = False\n",
    "        for fakultas in tmp_fakultas:\n",
    "            for judul in tmp_judul:\n",
    "                if(judul in kata_judul):\n",
    "                    if(fakultas in kata_judul[judul]):\n",
    "                        kata_judul[judul][fakultas] += 1\n",
    "                    else:\n",
    "                        kata_judul[judul][fakultas] = 1\n",
    "                else:\n",
    "                    kata_judul[judul] = {}\n",
    "                    kata_judul[judul][fakultas] = 1\n",
    "            for sinopsis in tmp_sinopsis:\n",
    "                if(sinopsis in kata_sinopsis):\n",
    "                    if(fakultas in kata_sinopsis[sinopsis]):\n",
    "                        kata_sinopsis[sinopsis][fakultas] += 1\n",
    "                    else:\n",
    "                        kata_sinopsis[sinopsis][fakultas] = 1\n",
    "                else:\n",
    "                    kata_sinopsis[sinopsis] = {}\n",
    "                    kata_sinopsis[sinopsis][fakultas] = 1\n",
    "                    \n",
    "        tmp_judul.clear()\n",
    "        tmp_sinopsis.clear()\n",
    "        tmp_fakultas.clear()\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        if not(i in stopwords):\n",
    "            \n",
    "            whitelist = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "            word = ''.join(filter(whitelist.__contains__, i))\n",
    "            word = word.lower()\n",
    "            \n",
    "            if len(word) > 1:#katanya masih ada setelah dibersihin, bukan cuma sisa 1 huruf\n",
    "                if rekam_judul:\n",
    "                    tmp_judul.append(word)\n",
    "                elif rekam_sinopsis:\n",
    "                    tmp_sinopsis.append(word)\n",
    "                elif rekam_fakultas:\n",
    "                    word = word.upper()\n",
    "                    tmp_fakultas.append(word)\n",
    "                    \n",
    "                    \n",
    "\n",
    "def predict_class(query):\n",
    "    words = query.split()\n",
    "    bobot_fakultas = {}\n",
    "    bobot_fakultas['FISIP'] = 0\n",
    "    bobot_fakultas['FASILKOM'] = 0\n",
    "    bobot_fakultas['FMIPA'] = 0\n",
    "    bobot_fakultas['FT'] = 0\n",
    "    bobot_fakultas['FK'] = 0\n",
    "    bobot_fakultas['FKG'] = 0\n",
    "    bobot_fakultas['FF'] = 0\n",
    "    bobot_fakultas['FIK'] = 0\n",
    "    bobot_fakultas['FKM'] = 0\n",
    "    bobot_fakultas['FH'] = 0\n",
    "    bobot_fakultas['FIB'] = 0\n",
    "    bobot_fakultas['FEB'] = 0\n",
    "    bobot_fakultas['FIA'] = 0\n",
    "    bobot_fakultas['FPSI'] = 0\n",
    "    \n",
    "    for word in words:\n",
    "        whitelist = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "        word = ''.join(filter(whitelist.__contains__, word))\n",
    "        if len(word) > 0:        \n",
    "            if word not in stopwords :\n",
    "                if word in kata_judul : #kalau gaada ya udah\n",
    "                    for fakultas in kata_judul[word]:\n",
    "                        bobot_fakultas[fakultas] += 2 * kata_judul[word][fakultas]\n",
    "                if word in kata_sinopsis : #kalau gaada ya udah\n",
    "                    for fakultas in kata_sinopsis[word]:\n",
    "                        bobot_fakultas[fakultas] += kata_sinopsis[word][fakultas]\n",
    "\n",
    "    best_bobot = 0\n",
    "    best_fakultas = \"FASILKOM\" #default\n",
    "    \n",
    "    for fakultas in bobot_fakultas:\n",
    "        if bobot_fakultas[fakultas] > best_bobot:\n",
    "            best_bobot = bobot_fakultas[fakultas]\n",
    "            best_fakultas = fakultas\n",
    "            \n",
    "    #print(bobot_fakultas)\n",
    "    return best_fakultas\n",
    "                      \n",
    "# print(tmp_judul)\n",
    "# print()\n",
    "# print(tmp_sinopsis)\n",
    "# print()\n",
    "# print(tmp_fakultas)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASILKOM\n",
      "FMIPA\n",
      "FEB\n"
     ]
    }
   ],
   "source": [
    "#input predict class masih berupa kalimat\n",
    "\n",
    "print(predict_class(\"object oriented programming\"))\n",
    "print(predict_class(\"scientific approach for biomolecular\"))\n",
    "print(predict_class(\"cost in financial aspect\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "dataset = open('korpus.txt', 'r')\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words += [\"<judul>\", \"</judul>\", \"<sinopsis>\", \"</sinopsis>\"]\n",
    "\n",
    "lines = dataset.readlines()\n",
    "len_lines = len(lines)\n",
    "counter = 0\n",
    "list_kalimat = []\n",
    "list_label = []\n",
    "\n",
    "for i in range(0,len_lines,3):\n",
    "    judul = lines[i].lower()\n",
    "    judul_arr = judul.split()\n",
    "    new_judul_arr = [word for word in judul_arr if word not in stop_words]\n",
    "    #print(new_judul_arr)\n",
    "    new_judul = \" \".join(new_judul_arr)\n",
    "    #print(new_judul)\n",
    "    sinopsis = lines[i+1].lower()\n",
    "    sinopsis_arr = sinopsis.split()\n",
    "    new_sinopsis_arr = [word for word in sinopsis_arr if word not in stop_words]\n",
    "    #print(new_sinopsis_arr)\n",
    "    new_sinopsis = \" \".join(new_sinopsis_arr)\n",
    "    #print(new_sinopsis)\n",
    "    \n",
    "    kalimat = new_judul + \" \" + new_sinopsis\n",
    "#     print(kalimat)\n",
    "#     print()\n",
    "    \n",
    "    fakultas_arr = lines[i+2].lower().split()\n",
    "    fakultas = fakultas_arr[1]\n",
    "    #print(fakultas)\n",
    "    \n",
    "    list_kalimat.append(kalimat)\n",
    "    list_label.append(fakultas)\n",
    "\n",
    "    \n",
    "print(len(list_kalimat))\n",
    "print(len(list_label))\n",
    "    \n",
    "\n",
    "\n",
    "# new_sentences_arr = [word for word in tokenized_words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3] + [4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,15,3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
