{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model dengan Fitur N-Gram\n",
    "\n",
    "File ini berisikan program untuk pembangunan model menggunakan fitur n-gram.\n",
    "Prediksi dilakukan terhadap label fakultas dan label rumpun.\n",
    "Eksperimen terhadap fitur bag of words menyangkut preprocessing, metode pembangunan model, dan jumlah label.\n",
    "\n",
    "Harap sebelum menjalankan program, install module yang diperlukan seperti nltk, spacy, dan en_core_web_sm\n",
    "\n",
    "Adapun untuk mempermudah pemahaman maksud dari X1, X2, X3, dan y1 dan y2 adalah :\n",
    "\n",
    "\n",
    "- X1 -> dataset dengan preprocessing tanpa stemming/lemmatisasi\n",
    "- X2 -> dataset dengan preprocessing dengan stemming\n",
    "- X3 -> dataset dengan preprocessing dengan lemmatisasi\n",
    "\n",
    "- y1 -> label fakultas (tujuan akhir)\n",
    "- y2 -> label rumpun (hanya pembanding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import stem\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = open('korpus-ver-2.txt', 'r', encoding=\"utf-8\")\n",
    "lines = dataset.readlines()\n",
    "len_lines = len(lines)\n",
    "counter = 0\n",
    "list_kalimat = []\n",
    "list_rumpun = []\n",
    "list_fakultas = []\n",
    "\n",
    "\n",
    "for i in range(0,len_lines,3):\n",
    "    line_i = lines[i]\n",
    "    judul = line_i\n",
    "    \n",
    "    judul = judul[8:-10] #buang tag <JUDUL> dari kalimat\n",
    "   \n",
    "    sinopsis = lines[i+1]\n",
    "    sinopsis = sinopsis[10:-13] #buang tag <SINOPSIS> dari kalimat\n",
    "   \n",
    "    \n",
    "    kalimat = judul + \" \" + sinopsis\n",
    "\n",
    "\n",
    "    fakultas_arr = lines[i+2].lower().split()\n",
    "    fakultas = fakultas_arr[1]\n",
    "    \n",
    "    \n",
    "    if(fakultas==\"rik\"):\n",
    "        label = \"rik\"\n",
    "    elif(fakultas==\"fmipa\"):\n",
    "        label = \"saintek\"\n",
    "    elif(fakultas==\"fasilkom\"):\n",
    "        label = \"saintek\"\n",
    "    elif(fakultas==\"ft\"):\n",
    "        label = \"saintek\"\n",
    "    elif(fakultas==\"fisip\"):\n",
    "        label = \"soshum\"\n",
    "    elif(fakultas==\"fib\"):\n",
    "        label = \"soshum\"\n",
    "    elif(fakultas==\"fh\"):\n",
    "        label = \"soshum\"\n",
    "    elif(fakultas==\"feb\"):\n",
    "        label = \"soshum\"\n",
    "    elif(fakultas==\"psikologi\"):\n",
    "        label = \"soshum\"\n",
    "    \n",
    "    list_kalimat.append(kalimat)\n",
    "    list_fakultas.append(fakultas)\n",
    "    list_rumpun.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(list_kalimat)\n",
    "list_cleaned = []\n",
    "list_stemmed = []\n",
    "list_lemmatized = []\n",
    "\n",
    "stemmer = stem.snowball.SnowballStemmer(\"english\")\n",
    "stop_words = stopwords.words('english')\n",
    "whitelist = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "# Load English tokenizer, tagger,  \n",
    "# parser, NER and word vectors \n",
    "nlp = spacy.load('en_core_web_sm') \n",
    "\n",
    "for i in range(N):\n",
    "    kalimat = list_kalimat[i]\n",
    "    \n",
    "    #lowercase\n",
    "    kalimat = kalimat.lower()\n",
    "    \n",
    "    #stopwords and tandabaca removal\n",
    "    words = kalimat.split(\" \")\n",
    "    kalimat_clean_arr = [''.join(filter(whitelist.__contains__, word)) for word in words if word not in stop_words]\n",
    "    \n",
    "    #stemming\n",
    "    kalimat_stemmed = ' '.join(stemmer.stem(w) for w in kalimat_clean_arr)\n",
    "    \n",
    "    # TODO lematisasi\n",
    "    kalimat_clean_str = ' '.join(kalimat_clean_arr)\n",
    "    spacy_kalimat_clean = nlp(kalimat_clean_str)\n",
    "    kalimat_lemma = ' '.join([w.lemma_ for w in spacy_kalimat_clean])\n",
    "    \n",
    "    kalimat_cleaned = ' '.join(kalimat_clean_arr)\n",
    "    \n",
    "    list_cleaned.append(kalimat_cleaned)\n",
    "    list_stemmed.append(kalimat_stemmed)\n",
    "    list_lemmatized.append(kalimat_lemma)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ekstraksi Fitur data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def EkstraksiNgram(tweet):\n",
    "    unigram = CountVectorizer(ngram_range=(1,1), min_df=2, max_features=2000)\n",
    "    unigram.fit(tweet)\n",
    "    unigram_matrix = unigram.transform(tweet).toarray()\n",
    "    bigram = CountVectorizer(ngram_range=(2,2), min_df=2, max_features=2000)\n",
    "    bigram.fit(tweet)\n",
    "    bigram_matrix = bigram.transform(tweet).toarray()\n",
    "    trigram = CountVectorizer(ngram_range=(3,3), min_df=2, max_features=2000)\n",
    "    trigram.fit(tweet)\n",
    "    trigram_matrix = trigram.transform(tweet).toarray()\n",
    "    return unigram_matrix, bigram_matrix, trigram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X1, _ = EkstraksiNgram(list_cleaned)\n",
    "\n",
    "_, X2, _ = EkstraksiNgram(list_stemmed)\n",
    "\n",
    "_, X3 ,_ = EkstraksiNgram(list_lemmatized)\n",
    "\n",
    "yf = list_fakultas\n",
    "yr = list_rumpun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "fasilkom\n",
      "saintek\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ind = [i for i in range(N)]\n",
    "\n",
    "ind_train,ind_test, _ , _ = train_test_split(ind, ind, test_size=0.25, random_state=1000)\n",
    "\n",
    "\n",
    "X_train1 = []\n",
    "X_test1 = []\n",
    "X_train2 = []\n",
    "X_test2 = []\n",
    "X_train3 = []\n",
    "X_test3 = []\n",
    "\n",
    "y_train1 = []\n",
    "y_test1 = []\n",
    "\n",
    "y_train2 = []\n",
    "y_test2 = []\n",
    "\n",
    "\n",
    "for i in ind_train:\n",
    "#     X_train1.append(list_cleaned[i])\n",
    "#     X_train2.append(list_stemmed[i])\n",
    "#     X_train3.append(list_lemmatized[i])\n",
    "    X_train1.append(X1[i])\n",
    "    X_train2.append(X2[i])\n",
    "    X_train3.append(X3[i])\n",
    "    \n",
    "    y_train1.append(yf[i])\n",
    "    y_train2.append(yr[i])\n",
    "    \n",
    "\n",
    "for i in ind_test:\n",
    "    X_test1.append(X1[i])\n",
    "    X_test2.append(X2[i])\n",
    "    X_test3.append(X3[i])\n",
    "    \n",
    "    y_test1.append(yf[i])\n",
    "    y_test2.append(yr[i])\n",
    "    \n",
    "print(X_test1[1])\n",
    "print()\n",
    "print(X_test2[1])\n",
    "print()\n",
    "print(y_test1[1])\n",
    "print(y_test2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pembangunan Model dan Akurasi\n",
    "\n",
    "#### Fungsi untuk confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False,  title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.colorbar()\n",
    "    tick_marks = numpy.arange(len(classes)) \n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\") \n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    #print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])): \n",
    "        plt.text(j, i, cm[i, j],  horizontalalignment=\"center\",  color=\"white\" if cm[i, j] > thresh else \"black\") \n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.ylabel('True label') \n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence untuk X1 dan Y1: 0.5734530429586004\n",
      "Logistic Regression untuk X1 dan Y1 : 0.5714285714285714\n",
      "\n",
      "Confidence untuk X2 dan Y1: 0.582111246156743\n",
      "Logistic Regression untuk X2 dan Y1 : 0.5844155844155844\n",
      "\n",
      "Confidence untuk X3 dan Y1: 0.5590243898552261\n",
      "Logistic Regression untuk X3 dan Y1 : 0.5844155844155844\n",
      "\n",
      "Logistic Regression untuk X1 dan Y2 : 0.7402597402597403\n",
      "Logistic Regression untuk X2 dan Y2 : 0.7662337662337663\n",
      "Logistic Regression untuk X3 dan Y2 : 0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier_log = LogisticRegression()\n",
    "\n",
    "classifier_log.fit(X_train1, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_log.fit(X_train1, y_train1)\n",
    "scores = cross_val_score(classifier_log, X_train1, y_train1, cv=5)\n",
    "print(\"Confidence untuk X1 dan Y1:\", scores.mean())\n",
    "\n",
    "predicted = classifier_log.predict(X_test1)\n",
    "score = classifier_log.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Logistic Regression untuk X1 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "# matrix = confusion_matrix(y_test1, predicted)\n",
    "# plot_confusion_matrix(matrix, classes = set(yf), title= 'CM for X1 and Y1')\n",
    "\n",
    "classifier_log.fit(X_train2, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_log.fit(X_train2, y_train1)\n",
    "scores = cross_val_score(classifier_log, X_train2, y_train1, cv=5)\n",
    "print(\"Confidence untuk X2 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_log.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Logistic Regression untuk X2 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_log.fit(X_train3, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_log.fit(X_train3, y_train1)\n",
    "scores = cross_val_score(classifier_log, X_train3, y_train1, cv=5)\n",
    "print(\"Confidence untuk X3 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_log.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Logistic Regression untuk X3 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "\n",
    "classifier_log.fit(X_train1, y_train2)\n",
    "predicted = classifier_log.predict(X_test1)\n",
    "score = classifier_log.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Logistic Regression untuk X1 dan Y2 :\", score)\n",
    "\n",
    "# matrix = confusion_matrix(y_test2, predicted)\n",
    "# plot_confusion_matrix(matrix, classes = set(yr), title= 'CM for X1 and Y2')\n",
    "\n",
    "classifier_log.fit(X_train2, y_train2)\n",
    "score = classifier_log.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Logistic Regression untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_log.fit(X_train3, y_train2)\n",
    "score = classifier_log.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Logistic Regression untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence untuk X1 dan Y1: 0.5980468231132124\n",
      "Gaussian NB untuk X1 dan Y1 : 0.6233766233766234\n",
      "\n",
      "Confidence untuk X2 dan Y1: 0.6231114225964166\n",
      "Gaussian NB untuk X2 dan Y1 : 0.6363636363636364\n",
      "\n",
      "Confidence untuk X3 dan Y1: 0.6445302467137358\n",
      "Gaussian NB untuk X3 dan Y1 : 0.6363636363636364\n",
      "\n",
      "Gaussian NB untuk X1 dan Y2 : 0.7792207792207793\n",
      "Gaussian NB untuk X2 dan Y2 : 0.7792207792207793\n",
      "Gaussian NB untuk X3 dan Y2 : 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier_gnb = GaussianNB()\n",
    "\n",
    "classifier_gnb.fit(X_train1, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_gnb.fit(X_train1, y_train1)\n",
    "scores = cross_val_score(classifier_gnb, X_train1, y_train1, cv=5)\n",
    "print(\"Confidence untuk X1 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_gnb.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Gaussian NB untuk X1 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_gnb.fit(X_train2, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_gnb.fit(X_train2, y_train1)\n",
    "scores = cross_val_score(classifier_gnb, X_train2, y_train1, cv=5)\n",
    "print(\"Confidence untuk X2 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_gnb.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Gaussian NB untuk X2 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_gnb.fit(X_train3, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_gnb.fit(X_train3, y_train1)\n",
    "scores = cross_val_score(classifier_gnb, X_train3, y_train1, cv=5)\n",
    "print(\"Confidence untuk X3 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_gnb.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Gaussian NB untuk X3 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_gnb.fit(X_train1, y_train2)\n",
    "score = classifier_gnb.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Gaussian NB untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_gnb.fit(X_train2, y_train2)\n",
    "score = classifier_gnb.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Gaussian NB untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_gnb.fit(X_train3, y_train2)\n",
    "score = classifier_gnb.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Gaussian NB untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence untuk X1 dan Y1: 0.6021385211378092\n",
      "Multinomial NB untuk X1 dan Y1 : 0.5714285714285714\n",
      "\n",
      "Confidence untuk X2 dan Y1: 0.6455204913041321\n",
      "Multinomial NB untuk X2 dan Y1 : 0.5844155844155844\n",
      "\n",
      "Confidence untuk X3 dan Y1: 0.6437225032061435\n",
      "Multinomial NB untuk X3 dan Y1 : 0.5584415584415584\n",
      "\n",
      "Multinomial NB untuk X1 dan Y2 : 0.7532467532467533\n",
      "Multinomial NB untuk X2 dan Y2 : 0.7272727272727273\n",
      "Multinomial NB untuk X3 dan Y2 : 0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier_mnb = MultinomialNB()\n",
    "\n",
    "classifier_mnb.fit(X_train1, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_mnb.fit(X_train1, y_train1)\n",
    "scores = cross_val_score(classifier_mnb, X_train1, y_train1, cv=5)\n",
    "print(\"Confidence untuk X1 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_mnb.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Multinomial NB untuk X1 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_mnb.fit(X_train2, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_mnb.fit(X_train2, y_train1)\n",
    "scores = cross_val_score(classifier_mnb, X_train2, y_train1, cv=5)\n",
    "print(\"Confidence untuk X2 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_mnb.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Multinomial NB untuk X2 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_mnb.fit(X_train3, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_mnb.fit(X_train3, y_train1)\n",
    "scores = cross_val_score(classifier_mnb, X_train3, y_train1, cv=5)\n",
    "print(\"Confidence untuk X3 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_mnb.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Multinomial NB untuk X3 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_mnb.fit(X_train1, y_train2)\n",
    "score = classifier_mnb.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Multinomial NB untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_mnb.fit(X_train2, y_train2)\n",
    "score = classifier_mnb.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Multinomial NB untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_mnb.fit(X_train3, y_train2)\n",
    "score = classifier_mnb.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Multinomial NB untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence untuk X1 dan Y1: 0.27399878938946726\n",
      "Random Forest untuk X1 dan Y1 : 0.2987012987012987\n",
      "\n",
      "Confidence untuk X2 dan Y1: 0.2526237885416667\n",
      "Random Forest untuk X2 dan Y1 : 0.2727272727272727\n",
      "\n",
      "Confidence untuk X3 dan Y1: 0.30536952237552983\n",
      "Random Forest untuk X3 dan Y1 : 0.3116883116883117\n",
      "\n",
      "Random Forest untuk X1 dan Y2 : 0.6883116883116883\n",
      "Random Forest untuk X2 dan Y2 : 0.7662337662337663\n",
      "Random Forest untuk X3 dan Y2 : 0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "classifier_rf = RandomForestClassifier()\n",
    "\n",
    "classifier_rf.fit(X_train1, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_rf.fit(X_train1, y_train1)\n",
    "scores = cross_val_score(classifier_rf, X_train1, y_train1, cv=5)\n",
    "print(\"Confidence untuk X1 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_rf.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Random Forest untuk X1 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_rf.fit(X_train2, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_rf.fit(X_train2, y_train1)\n",
    "scores = cross_val_score(classifier_rf, X_train2, y_train1, cv=5)\n",
    "print(\"Confidence untuk X2 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_rf.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Random Forest untuk X2 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_rf.fit(X_train3, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_rf.fit(X_train3, y_train1)\n",
    "scores = cross_val_score(classifier_rf, X_train3, y_train1, cv=5)\n",
    "print(\"Confidence untuk X3 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_rf.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Random Forest untuk X3 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_rf.fit(X_train1, y_train2)\n",
    "score = classifier_rf.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Random Forest untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_rf.fit(X_train2, y_train2)\n",
    "score = classifier_rf.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Random Forest untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_rf.fit(X_train3, y_train2)\n",
    "score = classifier_rf.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Random Forest untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence untuk X1 dan Y1: 0.1418241374720612\n",
      "AdaBoost untuk X1 dan Y1 : 0.09090909090909091\n",
      "\n",
      "Confidence untuk X2 dan Y1: 0.1418241374720612\n",
      "AdaBoost untuk X2 dan Y1 : 0.09090909090909091\n",
      "\n",
      "Confidence untuk X3 dan Y1: 0.1418241374720612\n",
      "AdaBoost untuk X3 dan Y1 : 0.09090909090909091\n",
      "\n",
      "AdaBoost untuk X1 dan Y2 : 0.6363636363636364\n",
      "AdaBoost untuk X2 dan Y2 : 0.6363636363636364\n",
      "AdaBoost untuk X3 dan Y2 : 0.6233766233766234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "classifier_ada = AdaBoostClassifier()\n",
    "\n",
    "classifier_ada.fit(X_train1, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_ada.fit(X_train1, y_train1)\n",
    "scores = cross_val_score(classifier_ada, X_train1, y_train1, cv=5)\n",
    "print(\"Confidence untuk X1 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_ada.score(X_test1, y_test1)\n",
    "\n",
    "print(\"AdaBoost untuk X1 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_ada.fit(X_train2, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_ada.fit(X_train2, y_train1)\n",
    "scores = cross_val_score(classifier_ada, X_train2, y_train1, cv=5)\n",
    "print(\"Confidence untuk X2 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_ada.score(X_test2, y_test1)\n",
    "\n",
    "print(\"AdaBoost untuk X2 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_ada.fit(X_train3, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_ada.fit(X_train3, y_train1)\n",
    "scores = cross_val_score(classifier_ada, X_train3, y_train1, cv=5)\n",
    "print(\"Confidence untuk X3 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_ada.score(X_test3, y_test1)\n",
    "\n",
    "print(\"AdaBoost untuk X3 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_ada.fit(X_train1, y_train2)\n",
    "score = classifier_ada.score(X_test1, y_test2)\n",
    "\n",
    "print(\"AdaBoost untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_ada.fit(X_train2, y_train2)\n",
    "score = classifier_ada.score(X_test2, y_test2)\n",
    "\n",
    "print(\"AdaBoost untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_ada.fit(X_train3, y_train2)\n",
    "score = classifier_ada.score(X_test3, y_test2)\n",
    "\n",
    "print(\"AdaBoost untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence untuk X1 dan Y1: 0.30912569351295704\n",
      "Decision Tree untuk X1 dan Y1 : 0.35064935064935066\n",
      "\n",
      "Confidence untuk X2 dan Y1: 0.23678661668831688\n",
      "Decision Tree untuk X2 dan Y1 : 0.3246753246753247\n",
      "\n",
      "Confidence untuk X3 dan Y1: 0.27297053418583295\n",
      "Decision Tree untuk X3 dan Y1 : 0.2987012987012987\n",
      "\n",
      "Decision Tree untuk X1 dan Y2 : 0.5064935064935064\n",
      "Decision Tree untuk X2 dan Y2 : 0.5324675324675324\n",
      "Decision Tree untuk X3 dan Y2 : 0.5194805194805194\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier_dt = DecisionTreeClassifier()\n",
    "\n",
    "classifier_dt.fit(X_train1, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_dt.fit(X_train1, y_train1)\n",
    "scores = cross_val_score(classifier_dt, X_train1, y_train1, cv=5)\n",
    "print(\"Confidence untuk X1 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_dt.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Decision Tree untuk X1 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_dt.fit(X_train2, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_dt.fit(X_train2, y_train1)\n",
    "scores = cross_val_score(classifier_dt, X_train2, y_train1, cv=5)\n",
    "print(\"Confidence untuk X2 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_dt.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Decision Tree untuk X2 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_dt.fit(X_train3, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_dt.fit(X_train3, y_train1)\n",
    "scores = cross_val_score(classifier_dt, X_train3, y_train1, cv=5)\n",
    "print(\"Confidence untuk X3 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_dt.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Decision Tree untuk X3 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_dt.fit(X_train1, y_train2)\n",
    "score = classifier_dt.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Decision Tree untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_dt.fit(X_train2, y_train2)\n",
    "score = classifier_dt.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Decision Tree untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_dt.fit(X_train3, y_train2)\n",
    "score = classifier_dt.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Decision Tree untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
