{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model dengan Fitur TF-IDF\n",
    "\n",
    "File ini berisikan program untuk pembangunan model menggunakan fitur tf-idf.\n",
    "Prediksi dilakukan terhadap label fakultas dan label rumpun.\n",
    "Eksperimen terhadap fitur bag of words menyangkut preprocessing, metode pembangunan model, dan jumlah label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = open('korpus-ver-2.txt', 'r', encoding=\"utf-8\")\n",
    "lines = dataset.readlines()\n",
    "len_lines = len(lines)\n",
    "counter = 0\n",
    "list_kalimat = []\n",
    "list_rumpun = []\n",
    "list_fakultas = []\n",
    "\n",
    "\n",
    "for i in range(0,len_lines,3):\n",
    "    line_i = lines[i]\n",
    "    judul = line_i\n",
    "    \n",
    "    judul = judul[8:-9] #buang tag <JUDUL> dari kalimat\n",
    "   \n",
    "    sinopsis = lines[i+1]\n",
    "    sinopsis = sinopsis[10:-13] #buang tag <SINOPSIS> dari kalimat\n",
    "   \n",
    "    \n",
    "    kalimat = judul + \" \" + sinopsis\n",
    "\n",
    "\n",
    "    fakultas_arr = lines[i+2].lower().split()\n",
    "    fakultas = fakultas_arr[1]\n",
    "    \n",
    "    \n",
    "    if(fakultas==\"rik\"):\n",
    "        label = \"rik\"\n",
    "    elif(fakultas==\"fmipa\"):\n",
    "        label = \"saintek\"\n",
    "    elif(fakultas==\"fasilkom\"):\n",
    "        label = \"saintek\"\n",
    "    elif(fakultas==\"ft\"):\n",
    "        label = \"saintek\"\n",
    "    elif(fakultas==\"fisip\"):\n",
    "        label = \"soshum\"\n",
    "    elif(fakultas==\"fib\"):\n",
    "        label = \"soshum\"\n",
    "    elif(fakultas==\"fh\"):\n",
    "        label = \"soshum\"\n",
    "    elif(fakultas==\"feb\"):\n",
    "        label = \"soshum\"\n",
    "    elif(fakultas==\"psikologi\"):\n",
    "        label = \"soshum\"\n",
    "    \n",
    "    list_kalimat.append(kalimat)\n",
    "    list_fakultas.append(fakultas)\n",
    "    list_rumpun.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(list_kalimat)\n",
    "list_cleaned = []\n",
    "list_stemmed = []\n",
    "list_lemmatized = []\n",
    "\n",
    "stemmer = stem.snowball.SnowballStemmer(\"english\")\n",
    "stop_words = stopwords.words('english')\n",
    "whitelist = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "for i in range(N):\n",
    "    kalimat = list_kalimat[i]\n",
    "    \n",
    "    #lowercase\n",
    "    kalimat = kalimat.lower()\n",
    "    \n",
    "    #stopwords and tandabaca removal\n",
    "    words = kalimat.split(\" \")\n",
    "    kalimat_clean_arr = [''.join(filter(whitelist.__contains__, word)) for word in words if word not in stop_words]\n",
    "    \n",
    "    #stemming\n",
    "    kalimat_stemmed = ' '.join(stemmer.stem(w) for w in kalimat_clean_arr)\n",
    "    \n",
    "    # TODO lematisasi\n",
    "    kalimat_lemma = kalimat_stemmed\n",
    "    \n",
    "    kalimat_cleaned = ' '.join(kalimat_clean_arr)\n",
    "    \n",
    "    list_cleaned.append(kalimat_cleaned)\n",
    "    list_stemmed.append(kalimat_stemmed)\n",
    "    list_lemmatized.append(kalimat_lemma)    \n",
    "    \n",
    "    \n",
    "# print(list_cleaned[0])\n",
    "# print()\n",
    "# print(list_stemmed[0])\n",
    "# print()\n",
    "# print(list_lemmatized[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ekstraksi Fitur data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer1 = TfidfVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer1.fit(list_cleaned)\n",
    "\n",
    "X1 = vectorizer1.transform(list_cleaned).toarray()\n",
    "\n",
    "vectorizer2 = TfidfVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer2.fit(list_stemmed)\n",
    "\n",
    "X2 = vectorizer2.transform(list_stemmed).toarray()\n",
    "\n",
    "vectorizer3 = TfidfVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer3.fit(list_lemmatized)\n",
    "\n",
    "X3 = vectorizer3.transform(list_lemmatized).toarray()\n",
    "\n",
    "\n",
    "yf = list_fakultas\n",
    "yr = list_rumpun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "\n",
      "fib\n",
      "soshum\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ind = [i for i in range(N)]\n",
    "\n",
    "ind_train,ind_test, _ , _ = train_test_split(ind, ind, test_size=0.25, random_state=1000)\n",
    "\n",
    "\n",
    "X_train1 = []\n",
    "X_test1 = []\n",
    "X_train2 = []\n",
    "X_test2 = []\n",
    "X_train3 = []\n",
    "X_test3 = []\n",
    "\n",
    "y_train1 = []\n",
    "y_test1 = []\n",
    "\n",
    "y_train2 = []\n",
    "y_test2 = []\n",
    "\n",
    "\n",
    "for i in ind_train:\n",
    "#     X_train1.append(list_cleaned[i])\n",
    "#     X_train2.append(list_stemmed[i])\n",
    "#     X_train3.append(list_lemmatized[i])\n",
    "    X_train1.append(X1[i])\n",
    "    X_train2.append(X2[i])\n",
    "    X_train3.append(X3[i])\n",
    "    \n",
    "    y_train1.append(yf[i])\n",
    "    y_train2.append(yr[i])\n",
    "    \n",
    "\n",
    "for i in ind_test:\n",
    "    X_test1.append(X1[i])\n",
    "    X_test2.append(X2[i])\n",
    "    X_test3.append(X3[i])\n",
    "    \n",
    "    y_test1.append(yf[i])\n",
    "    y_test2.append(yr[i])\n",
    "    \n",
    "print(X_test1[1])\n",
    "print()\n",
    "print(X_test2[1])\n",
    "print()\n",
    "print(y_test1[1])\n",
    "print(y_test2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pembangunan Model dan Akurasi\n",
    "\n",
    "#### Fungsi untuk confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False,  title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.colorbar()\n",
    "    tick_marks = numpy.arange(len(classes)) \n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\") \n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    #print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])): \n",
    "        plt.text(j, i, cm[i, j],  horizontalalignment=\"center\",  color=\"white\" if cm[i, j] > thresh else \"black\") \n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.ylabel('True label') \n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression untuk X1 dan Y1 : 0.2698412698412698\n",
      "Logistic Regression untuk X2 dan Y1 : 0.30158730158730157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression untuk X3 dan Y1 : 0.30158730158730157\n",
      "Logistic Regression untuk X1 dan Y2 : 0.6190476190476191\n",
      "Logistic Regression untuk X2 dan Y2 : 0.6507936507936508\n",
      "Logistic Regression untuk X3 dan Y2 : 0.6507936507936508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier_log = LogisticRegression()\n",
    "\n",
    "classifier_log.fit(X_train1, y_train1)\n",
    "predicted = classifier_log.predict(X_test1)\n",
    "score = classifier_log.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Logistic Regression untuk X1 dan Y1 :\", score)\n",
    "\n",
    "# matrix = confusion_matrix(y_test1, predicted)\n",
    "# plot_confusion_matrix(matrix, classes = set(yf), title= 'CM for X1 and Y1')\n",
    "\n",
    "classifier_log.fit(X_train2, y_train1)\n",
    "score = classifier_log.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Logistic Regression untuk X2 dan Y1 :\", score)\n",
    "\n",
    "classifier_log.fit(X_train3, y_train1)\n",
    "score = classifier_log.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Logistic Regression untuk X3 dan Y1 :\", score)\n",
    "\n",
    "\n",
    "classifier_log.fit(X_train1, y_train2)\n",
    "predicted = classifier_log.predict(X_test1)\n",
    "score = classifier_log.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Logistic Regression untuk X1 dan Y2 :\", score)\n",
    "\n",
    "# matrix = confusion_matrix(y_test2, predicted)\n",
    "# plot_confusion_matrix(matrix, classes = set(yr), title= 'CM for X1 and Y2')\n",
    "\n",
    "classifier_log.fit(X_train2, y_train2)\n",
    "score = classifier_log.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Logistic Regression untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_log.fit(X_train3, y_train2)\n",
    "score = classifier_log.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Logistic Regression untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB untuk X1 dan Y1 : 0.3968253968253968\n",
      "Gaussian NB untuk X2 dan Y1 : 0.4126984126984127\n",
      "Gaussian NB untuk X3 dan Y1 : 0.4126984126984127\n",
      "Gaussian NB untuk X1 dan Y2 : 0.7777777777777778\n",
      "Gaussian NB untuk X2 dan Y2 : 0.8253968253968254\n",
      "Gaussian NB untuk X3 dan Y2 : 0.8253968253968254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier_gnb = GaussianNB()\n",
    "\n",
    "classifier_gnb.fit(X_train1, y_train1)\n",
    "score = classifier_gnb.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Gaussian NB untuk X1 dan Y1 :\", score)\n",
    "\n",
    "classifier_gnb.fit(X_train2, y_train1)\n",
    "score = classifier_gnb.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Gaussian NB untuk X2 dan Y1 :\", score)\n",
    "\n",
    "classifier_gnb.fit(X_train3, y_train1)\n",
    "score = classifier_gnb.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Gaussian NB untuk X3 dan Y1 :\", score)\n",
    "\n",
    "classifier_gnb.fit(X_train1, y_train2)\n",
    "score = classifier_gnb.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Gaussian NB untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_gnb.fit(X_train2, y_train2)\n",
    "score = classifier_gnb.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Gaussian NB untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_gnb.fit(X_train3, y_train2)\n",
    "score = classifier_gnb.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Gaussian NB untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB untuk X1 dan Y1 : 0.2222222222222222\n",
      "Multinomial NB untuk X2 dan Y1 : 0.2222222222222222\n",
      "Multinomial NB untuk X3 dan Y1 : 0.2222222222222222\n",
      "Multinomial NB untuk X1 dan Y2 : 0.6190476190476191\n",
      "Multinomial NB untuk X2 dan Y2 : 0.6190476190476191\n",
      "Multinomial NB untuk X3 dan Y2 : 0.6190476190476191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier_mnb = MultinomialNB()\n",
    "\n",
    "classifier_mnb.fit(X_train1, y_train1)\n",
    "score = classifier_mnb.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Multinomial NB untuk X1 dan Y1 :\", score)\n",
    "\n",
    "classifier_mnb.fit(X_train2, y_train1)\n",
    "score = classifier_mnb.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Multinomial NB untuk X2 dan Y1 :\", score)\n",
    "\n",
    "classifier_mnb.fit(X_train3, y_train1)\n",
    "score = classifier_mnb.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Multinomial NB untuk X3 dan Y1 :\", score)\n",
    "\n",
    "classifier_mnb.fit(X_train1, y_train2)\n",
    "score = classifier_mnb.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Multinomial NB untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_mnb.fit(X_train2, y_train2)\n",
    "score = classifier_mnb.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Multinomial NB untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_mnb.fit(X_train3, y_train2)\n",
    "score = classifier_mnb.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Multinomial NB untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest untuk X1 dan Y1 : 0.30158730158730157\n",
      "Random Forest untuk X2 dan Y1 : 0.23809523809523808\n",
      "Random Forest untuk X3 dan Y1 : 0.36507936507936506\n",
      "Random Forest untuk X1 dan Y2 : 0.6190476190476191\n",
      "Random Forest untuk X2 dan Y2 : 0.6507936507936508\n",
      "Random Forest untuk X3 dan Y2 : 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "classifier_rf = RandomForestClassifier()\n",
    "\n",
    "classifier_rf.fit(X_train1, y_train1)\n",
    "score = classifier_rf.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Random Forest untuk X1 dan Y1 :\", score)\n",
    "\n",
    "classifier_rf.fit(X_train2, y_train1)\n",
    "score = classifier_rf.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Random Forest untuk X2 dan Y1 :\", score)\n",
    "\n",
    "classifier_rf.fit(X_train3, y_train1)\n",
    "score = classifier_rf.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Random Forest untuk X3 dan Y1 :\", score)\n",
    "\n",
    "classifier_rf.fit(X_train1, y_train2)\n",
    "score = classifier_rf.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Random Forest untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_rf.fit(X_train2, y_train2)\n",
    "score = classifier_rf.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Random Forest untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_rf.fit(X_train3, y_train2)\n",
    "score = classifier_rf.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Random Forest untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost untuk X1 dan Y1 : 0.12698412698412698\n",
      "AdaBoost untuk X2 dan Y1 : 0.12698412698412698\n",
      "AdaBoost untuk X3 dan Y1 : 0.12698412698412698\n",
      "AdaBoost untuk X1 dan Y2 : 0.6507936507936508\n",
      "AdaBoost untuk X2 dan Y2 : 0.6349206349206349\n",
      "AdaBoost untuk X3 dan Y2 : 0.6349206349206349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "classifier_ada = AdaBoostClassifier()\n",
    "\n",
    "classifier_ada.fit(X_train1, y_train1)\n",
    "score = classifier_ada.score(X_test1, y_test1)\n",
    "\n",
    "print(\"AdaBoost untuk X1 dan Y1 :\", score)\n",
    "\n",
    "classifier_ada.fit(X_train2, y_train1)\n",
    "score = classifier_ada.score(X_test2, y_test1)\n",
    "\n",
    "print(\"AdaBoost untuk X2 dan Y1 :\", score)\n",
    "\n",
    "classifier_ada.fit(X_train3, y_train1)\n",
    "score = classifier_ada.score(X_test3, y_test1)\n",
    "\n",
    "print(\"AdaBoost untuk X3 dan Y1 :\", score)\n",
    "\n",
    "classifier_ada.fit(X_train1, y_train2)\n",
    "score = classifier_ada.score(X_test1, y_test2)\n",
    "\n",
    "print(\"AdaBoost untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_ada.fit(X_train2, y_train2)\n",
    "score = classifier_ada.score(X_test2, y_test2)\n",
    "\n",
    "print(\"AdaBoost untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_ada.fit(X_train3, y_train2)\n",
    "score = classifier_ada.score(X_test3, y_test2)\n",
    "\n",
    "print(\"AdaBoost untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree untuk X1 dan Y1 : 0.2698412698412698\n",
      "Decision Tree untuk X2 dan Y1 : 0.2857142857142857\n",
      "Decision Tree untuk X3 dan Y1 : 0.2857142857142857\n",
      "Decision Tree untuk X1 dan Y2 : 0.746031746031746\n",
      "Decision Tree untuk X2 dan Y2 : 0.8095238095238095\n",
      "Decision Tree untuk X3 dan Y2 : 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier_dt = DecisionTreeClassifier()\n",
    "\n",
    "classifier_dt.fit(X_train1, y_train1)\n",
    "score = classifier_dt.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Decision Tree untuk X1 dan Y1 :\", score)\n",
    "\n",
    "classifier_dt.fit(X_train2, y_train1)\n",
    "score = classifier_dt.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Decision Tree untuk X2 dan Y1 :\", score)\n",
    "\n",
    "classifier_dt.fit(X_train3, y_train1)\n",
    "score = classifier_dt.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Decision Tree untuk X3 dan Y1 :\", score)\n",
    "\n",
    "classifier_dt.fit(X_train1, y_train2)\n",
    "score = classifier_dt.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Decision Tree untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_dt.fit(X_train2, y_train2)\n",
    "score = classifier_dt.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Decision Tree untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_dt.fit(X_train3, y_train2)\n",
    "score = classifier_dt.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Decision Tree untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
