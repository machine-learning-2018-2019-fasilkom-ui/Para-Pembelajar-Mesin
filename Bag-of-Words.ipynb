{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model dengan Fitur Bag of Words\n",
    "\n",
    "File ini berisikan program untuk pembangunan model menggunakan fitur bag of words.\n",
    "Prediksi dilakukan terhadap label fakultas dan label rumpun.\n",
    "Eksperimen terhadap fitur bag of words menyangkut preprocessing, metode pembangunan model, dan jumlah label.\n",
    "\n",
    "Harap sebelum menjalankan program, install module yang diperlukan seperti nltk, spacy, dan en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import stem\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = open('korpus-ver-2.txt', 'r', encoding=\"utf-8\")\n",
    "lines = dataset.readlines()\n",
    "len_lines = len(lines)\n",
    "counter = 0\n",
    "list_kalimat = []\n",
    "list_rumpun = []\n",
    "list_fakultas = []\n",
    "\n",
    "\n",
    "for i in range(0,len_lines,3):\n",
    "    line_i = lines[i]\n",
    "    judul = line_i\n",
    "    \n",
    "    judul = judul[8:-10] #buang tag <JUDUL> dari kalimat\n",
    "   \n",
    "    sinopsis = lines[i+1]\n",
    "    sinopsis = sinopsis[10:-13] #buang tag <SINOPSIS> dari kalimat\n",
    "   \n",
    "    \n",
    "    kalimat = judul + \" \" + sinopsis\n",
    "\n",
    "\n",
    "    fakultas_arr = lines[i+2].lower().split()\n",
    "    fakultas = fakultas_arr[1]\n",
    "    \n",
    "    \n",
    "    if(fakultas==\"rik\"):\n",
    "        label = \"rik\"\n",
    "    elif(fakultas==\"fmipa\"):\n",
    "        label = \"saintek\"\n",
    "    elif(fakultas==\"fasilkom\"):\n",
    "        label = \"saintek\"\n",
    "    elif(fakultas==\"ft\"):\n",
    "        label = \"saintek\"\n",
    "    elif(fakultas==\"fisip\"):\n",
    "        label = \"soshum\"\n",
    "    elif(fakultas==\"fib\"):\n",
    "        label = \"soshum\"\n",
    "    elif(fakultas==\"fh\"):\n",
    "        label = \"soshum\"\n",
    "    elif(fakultas==\"feb\"):\n",
    "        label = \"soshum\"\n",
    "    elif(fakultas==\"psikologi\"):\n",
    "        label = \"soshum\"\n",
    "    \n",
    "    list_kalimat.append(kalimat)\n",
    "    list_fakultas.append(fakultas)\n",
    "    list_rumpun.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(list_kalimat)\n",
    "list_cleaned = []\n",
    "pos_tag = dict()\n",
    "list_stemmed = []\n",
    "list_lemmatized = []\n",
    "\n",
    "stemmer = stem.snowball.SnowballStemmer(\"english\")\n",
    "stop_words = stopwords.words('english')\n",
    "whitelist = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "# Load English tokenizer, tagger,  \n",
    "# parser, NER and word vectors \n",
    "nlp = spacy.load('en_core_web_sm') \n",
    "\n",
    "for i in range(N):\n",
    "    kalimat = list_kalimat[i]\n",
    "    \n",
    "    #lowercase\n",
    "    kalimat = kalimat.lower()\n",
    "    \n",
    "    #stopwords and punctuation removal\n",
    "    words = kalimat.split(\" \")\n",
    "    kalimat_clean_arr = [''.join(filter(whitelist.__contains__, word)) for word in words if word not in stop_words]\n",
    "    \n",
    "    # stemming\n",
    "    kalimat_stemmed = ' '.join(stemmer.stem(w) for w in kalimat_clean_arr)\n",
    "    \n",
    "    # lematisasi\n",
    "    kalimat_clean_str = ' '.join(kalimat_clean_arr)\n",
    "    spacy_kalimat_clean = nlp(kalimat_clean_str)\n",
    "    kalimat_lemma = ' '.join([w.lemma_ for w in spacy_kalimat_clean])\n",
    "    \n",
    "    kalimat_cleaned = ' '.join(kalimat_clean_arr)\n",
    "    \n",
    "    list_cleaned.append(kalimat_cleaned)\n",
    "    list_stemmed.append(kalimat_stemmed)\n",
    "    list_lemmatized.append(kalimat_lemma)    \n",
    "    \n",
    "    \n",
    "# print(list_cleaned[0])\n",
    "# print()\n",
    "# print(list_stemmed[0])\n",
    "# print()\n",
    "# print(list_lemmatized[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ekstraksi Fitur data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer1 = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer1.fit(list_cleaned)\n",
    "\n",
    "X1 = vectorizer1.transform(list_cleaned).toarray()\n",
    "\n",
    "vectorizer2 = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer2.fit(list_stemmed)\n",
    "\n",
    "X2 = vectorizer2.transform(list_stemmed).toarray()\n",
    "\n",
    "vectorizer3 = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer3.fit(list_lemmatized)\n",
    "\n",
    "X3 = vectorizer3.transform(list_lemmatized).toarray()\n",
    "\n",
    "\n",
    "yf = list_fakultas\n",
    "yr = list_rumpun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "fasilkom\n",
      "saintek\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ind = [i for i in range(N)]\n",
    "\n",
    "ind_train,ind_test, _ , _ = train_test_split(ind, ind, test_size=0.25, random_state=1000)\n",
    "\n",
    "\n",
    "X_train1 = []\n",
    "X_test1 = []\n",
    "X_train2 = []\n",
    "X_test2 = []\n",
    "X_train3 = []\n",
    "X_test3 = []\n",
    "\n",
    "y_train1 = []\n",
    "y_test1 = []\n",
    "\n",
    "y_train2 = []\n",
    "y_test2 = []\n",
    "\n",
    "\n",
    "for i in ind_train:\n",
    "#     X_train1.append(list_cleaned[i])\n",
    "#     X_train2.append(list_stemmed[i])\n",
    "#     X_train3.append(list_lemmatized[i])\n",
    "    X_train1.append(X1[i])\n",
    "    X_train2.append(X2[i])\n",
    "    X_train3.append(X3[i])\n",
    "    \n",
    "    y_train1.append(yf[i])\n",
    "    y_train2.append(yr[i])\n",
    "    \n",
    "\n",
    "for i in ind_test:\n",
    "    X_test1.append(X1[i])\n",
    "    X_test2.append(X2[i])\n",
    "    X_test3.append(X3[i])\n",
    "    \n",
    "    y_test1.append(yf[i])\n",
    "    y_test2.append(yr[i])\n",
    "    \n",
    "print(X_test1[1])\n",
    "print()\n",
    "print(X_test2[1])\n",
    "print()\n",
    "print(y_test1[1])\n",
    "print(y_test2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pembangunan Model dan Akurasi\n",
    "\n",
    "#### Fungsi untuk confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False,  title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.colorbar()\n",
    "    tick_marks = numpy.arange(len(classes)) \n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\") \n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    #print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])): \n",
    "        plt.text(j, i, cm[i, j],  horizontalalignment=\"center\",  color=\"white\" if cm[i, j] > thresh else \"black\") \n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.ylabel('True label') \n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_accuracy(preds, acts):\n",
    "    total = len(preds)\n",
    "    counter = 0\n",
    "    for i in range(total):\n",
    "        if(preds[i] == acts[i]):\n",
    "            counter += 1\n",
    "            \n",
    "    return counter / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence untuk X1 dan Y1: 0.8118979321655045\n",
      "Logistic Regression untuk X1 dan Y1 : 0.8701298701298701\n",
      "\n",
      "Confidence untuk X2 dan Y1: 0.8204850211773278\n",
      "Logistic Regression untuk X2 dan Y1 : 0.8831168831168831\n",
      "\n",
      "Confidence untuk X3 dan Y1: 0.8150553569516076\n",
      "Logistic Regression untuk X3 dan Y1 : 0.8571428571428571\n",
      "\n",
      "Logistic Regression untuk X1 dan Y2 : 0.948051948051948\n",
      "Logistic Regression untuk X2 dan Y2 : 0.922077922077922\n",
      "Logistic Regression untuk X3 dan Y2 : 0.935064935064935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier_log = LogisticRegression(multi_class='ovr',solver='liblinear')\n",
    "\n",
    "# Cross Validation\n",
    "classifier_log.fit(X_train1, y_train1)\n",
    "scores = cross_val_score(classifier_log, X_train1, y_train1, cv=5)\n",
    "print(\"Confidence untuk X1 dan Y1:\", scores.mean())\n",
    "\n",
    "predicted = classifier_log.predict(X_test1)\n",
    "score = classifier_log.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Logistic Regression untuk X1 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "# matrix = confusion_matrix(y_test1, predicted)\n",
    "# plot_confusion_matrix(matrix, classes = set(yf), title= 'CM for X1 and Y1')\n",
    "\n",
    "classifier_log.fit(X_train2, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_log.fit(X_train2, y_train1)\n",
    "scores = cross_val_score(classifier_log, X_train2, y_train1, cv=5)\n",
    "print(\"Confidence untuk X2 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_log.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Logistic Regression untuk X2 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_log.fit(X_train3, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_log.fit(X_train3, y_train1)\n",
    "scores = cross_val_score(classifier_log, X_train3, y_train1, cv=5)\n",
    "print(\"Confidence untuk X3 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_log.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Logistic Regression untuk X3 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "\n",
    "classifier_log.fit(X_train1, y_train2)\n",
    "predicted = classifier_log.predict(X_test1)\n",
    "score = classifier_log.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Logistic Regression untuk X1 dan Y2 :\", score)\n",
    "\n",
    "# matrix = confusion_matrix(y_test2, predicted)\n",
    "# plot_confusion_matrix(matrix, classes = set(yr), title= 'CM for X1 and Y2')\n",
    "\n",
    "classifier_log.fit(X_train2, y_train2)\n",
    "score = classifier_log.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Logistic Regression untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_log.fit(X_train3, y_train2)\n",
    "score = classifier_log.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Logistic Regression untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence untuk X1 dan Y1: 0.7403256459545069\n",
      "Gaussian NB untuk X1 dan Y1 : 0.7662337662337663\n",
      "\n",
      "Confidence untuk X2 dan Y1: 0.6840638186516538\n",
      "Gaussian NB untuk X2 dan Y1 : 0.7142857142857143\n",
      "\n",
      "Confidence untuk X3 dan Y1: 0.7136870739875352\n",
      "Gaussian NB untuk X3 dan Y1 : 0.7402597402597403\n",
      "\n",
      "Gaussian NB untuk X1 dan Y2 : 0.8701298701298701\n",
      "Gaussian NB untuk X2 dan Y2 : 0.8831168831168831\n",
      "Gaussian NB untuk X3 dan Y2 : 0.8961038961038961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier_gnb = GaussianNB()\n",
    "\n",
    "classifier_gnb.fit(X_train1, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_gnb.fit(X_train1, y_train1)\n",
    "scores = cross_val_score(classifier_gnb, X_train1, y_train1, cv=5)\n",
    "print(\"Confidence untuk X1 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_gnb.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Gaussian NB untuk X1 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_gnb.fit(X_train2, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_gnb.fit(X_train2, y_train1)\n",
    "scores = cross_val_score(classifier_gnb, X_train2, y_train1, cv=5)\n",
    "print(\"Confidence untuk X2 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_gnb.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Gaussian NB untuk X2 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_gnb.fit(X_train3, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_gnb.fit(X_train3, y_train1)\n",
    "scores = cross_val_score(classifier_gnb, X_train3, y_train1, cv=5)\n",
    "print(\"Confidence untuk X3 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_gnb.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Gaussian NB untuk X3 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_gnb.fit(X_train1, y_train2)\n",
    "score = classifier_gnb.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Gaussian NB untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_gnb.fit(X_train2, y_train2)\n",
    "score = classifier_gnb.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Gaussian NB untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_gnb.fit(X_train3, y_train2)\n",
    "score = classifier_gnb.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Gaussian NB untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence untuk X1 dan Y1: 0.7941453627761185\n",
      "Multinomial NB untuk X1 dan Y1 : 0.8441558441558441\n",
      "\n",
      "Confidence untuk X2 dan Y1: 0.7910643887039664\n",
      "Multinomial NB untuk X2 dan Y1 : 0.8571428571428571\n",
      "\n",
      "Confidence untuk X3 dan Y1: 0.7953197078529025\n",
      "Multinomial NB untuk X3 dan Y1 : 0.8441558441558441\n",
      "\n",
      "Multinomial NB untuk X1 dan Y2 : 0.9090909090909091\n",
      "Multinomial NB untuk X2 dan Y2 : 0.922077922077922\n",
      "Multinomial NB untuk X3 dan Y2 : 0.922077922077922\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier_mnb = MultinomialNB()\n",
    "\n",
    "classifier_mnb.fit(X_train1, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_mnb.fit(X_train1, y_train1)\n",
    "scores = cross_val_score(classifier_mnb, X_train1, y_train1, cv=5)\n",
    "print(\"Confidence untuk X1 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_mnb.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Multinomial NB untuk X1 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_mnb.fit(X_train2, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_mnb.fit(X_train2, y_train1)\n",
    "scores = cross_val_score(classifier_mnb, X_train2, y_train1, cv=5)\n",
    "print(\"Confidence untuk X2 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_mnb.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Multinomial NB untuk X2 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_mnb.fit(X_train3, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_mnb.fit(X_train3, y_train1)\n",
    "scores = cross_val_score(classifier_mnb, X_train3, y_train1, cv=5)\n",
    "print(\"Confidence untuk X3 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_mnb.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Multinomial NB untuk X3 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_mnb.fit(X_train1, y_train2)\n",
    "score = classifier_mnb.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Multinomial NB untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_mnb.fit(X_train2, y_train2)\n",
    "score = classifier_mnb.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Multinomial NB untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_mnb.fit(X_train3, y_train2)\n",
    "score = classifier_mnb.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Multinomial NB untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence untuk X1 dan Y1: 0.4192019011097898\n",
      "Random Forest untuk X1 dan Y1 : 0.6493506493506493\n",
      "\n",
      "Confidence untuk X2 dan Y1: 0.4028880894980381\n",
      "Random Forest untuk X2 dan Y1 : 0.6363636363636364\n",
      "\n",
      "Confidence untuk X3 dan Y1: 0.5006723888779379\n",
      "Random Forest untuk X3 dan Y1 : 0.5714285714285714\n",
      "\n",
      "Random Forest untuk X1 dan Y2 : 0.7272727272727273\n",
      "Random Forest untuk X2 dan Y2 : 0.7402597402597403\n",
      "Random Forest untuk X3 dan Y2 : 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "classifier_rf = RandomForestClassifier()\n",
    "\n",
    "classifier_rf.fit(X_train1, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_rf.fit(X_train1, y_train1)\n",
    "scores = cross_val_score(classifier_rf, X_train1, y_train1, cv=5)\n",
    "print(\"Confidence untuk X1 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_rf.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Random Forest untuk X1 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_rf.fit(X_train2, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_rf.fit(X_train2, y_train1)\n",
    "scores = cross_val_score(classifier_rf, X_train2, y_train1, cv=5)\n",
    "print(\"Confidence untuk X2 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_rf.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Random Forest untuk X2 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_rf.fit(X_train3, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_rf.fit(X_train3, y_train1)\n",
    "scores = cross_val_score(classifier_rf, X_train3, y_train1, cv=5)\n",
    "print(\"Confidence untuk X3 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_rf.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Random Forest untuk X3 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_rf.fit(X_train1, y_train2)\n",
    "score = classifier_rf.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Random Forest untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_rf.fit(X_train2, y_train2)\n",
    "score = classifier_rf.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Random Forest untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_rf.fit(X_train3, y_train2)\n",
    "score = classifier_rf.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Random Forest untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence untuk X1 dan Y1: 0.12148715149350578\n",
      "SVC untuk X1 dan Y1 : 0.03896103896103896\n",
      "\n",
      "Confidence untuk X2 dan Y1: 0.12148715149350578\n",
      "SVC untuk X2 dan Y1 : 0.05194805194805195\n",
      "\n",
      "Confidence untuk X3 dan Y1: 0.12148715149350578\n",
      "SVC untuk X3 dan Y1 : 0.03896103896103896\n",
      "\n",
      "SVC untuk X1 dan Y2 : 0.6493506493506493\n",
      "SVC untuk X2 dan Y2 : 0.6623376623376623\n",
      "SVC untuk X3 dan Y2 : 0.6493506493506493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier_svc = SVC(gamma='auto')\n",
    "\n",
    "classifier_svc.fit(X_train1, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_svc.fit(X_train1, y_train1)\n",
    "scores = cross_val_score(classifier_svc, X_train1, y_train1, cv=5)\n",
    "print(\"Confidence untuk X1 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_svc.score(X_test1, y_test1)\n",
    "\n",
    "print(\"SVC untuk X1 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_svc.fit(X_train2, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_svc.fit(X_train2, y_train1)\n",
    "scores = cross_val_score(classifier_svc, X_train2, y_train1, cv=5)\n",
    "print(\"Confidence untuk X2 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_svc.score(X_test2, y_test1)\n",
    "\n",
    "print(\"SVC untuk X2 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_svc.fit(X_train3, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_svc.fit(X_train3, y_train1)\n",
    "scores = cross_val_score(classifier_svc, X_train3, y_train1, cv=5)\n",
    "print(\"Confidence untuk X3 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_svc.score(X_test3, y_test1)\n",
    "\n",
    "print(\"SVC untuk X3 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_svc.fit(X_train1, y_train2)\n",
    "score = classifier_svc.score(X_test1, y_test2)\n",
    "\n",
    "print(\"SVC untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_svc.fit(X_train2, y_train2)\n",
    "score = classifier_svc.score(X_test2, y_test2)\n",
    "\n",
    "print(\"SVC untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_svc.fit(X_train3, y_train2)\n",
    "score = classifier_svc.score(X_test3, y_test2)\n",
    "\n",
    "print(\"SVC untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence untuk X1 dan Y1: 0.18479070385437413\n",
      "AdaBoost untuk X1 dan Y1 : 0.15584415584415584\n",
      "\n",
      "Confidence untuk X2 dan Y1: 0.17503460629339854\n",
      "AdaBoost untuk X2 dan Y1 : 0.15584415584415584\n",
      "\n",
      "Confidence untuk X3 dan Y1: 0.18479070385437413\n",
      "AdaBoost untuk X3 dan Y1 : 0.15584415584415584\n",
      "\n",
      "AdaBoost untuk X1 dan Y2 : 0.6753246753246753\n",
      "AdaBoost untuk X2 dan Y2 : 0.6623376623376623\n",
      "AdaBoost untuk X3 dan Y2 : 0.6233766233766234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "classifier_ada = AdaBoostClassifier()\n",
    "\n",
    "classifier_ada.fit(X_train1, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_ada.fit(X_train1, y_train1)\n",
    "scores = cross_val_score(classifier_ada, X_train1, y_train1, cv=5)\n",
    "print(\"Confidence untuk X1 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_ada.score(X_test1, y_test1)\n",
    "\n",
    "print(\"AdaBoost untuk X1 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_ada.fit(X_train2, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_ada.fit(X_train2, y_train1)\n",
    "scores = cross_val_score(classifier_ada, X_train2, y_train1, cv=5)\n",
    "print(\"Confidence untuk X2 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_ada.score(X_test2, y_test1)\n",
    "\n",
    "print(\"AdaBoost untuk X2 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_ada.fit(X_train3, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_ada.fit(X_train3, y_train1)\n",
    "scores = cross_val_score(classifier_ada, X_train3, y_train1, cv=5)\n",
    "print(\"Confidence untuk X3 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_ada.score(X_test3, y_test1)\n",
    "\n",
    "print(\"AdaBoost untuk X3 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_ada.fit(X_train1, y_train2)\n",
    "score = classifier_ada.score(X_test1, y_test2)\n",
    "\n",
    "print(\"AdaBoost untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_ada.fit(X_train2, y_train2)\n",
    "score = classifier_ada.score(X_test2, y_test2)\n",
    "\n",
    "print(\"AdaBoost untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_ada.fit(X_train3, y_train2)\n",
    "score = classifier_ada.score(X_test3, y_test2)\n",
    "\n",
    "print(\"AdaBoost untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence untuk X1 dan Y1: 0.5338493946004796\n",
      "Decision Tree untuk X1 dan Y1 : 0.5324675324675324\n",
      "\n",
      "Confidence untuk X2 dan Y1: 0.6188546284203601\n",
      "Decision Tree untuk X2 dan Y1 : 0.5974025974025974\n",
      "\n",
      "Confidence untuk X3 dan Y1: 0.5401433353231625\n",
      "Decision Tree untuk X3 dan Y1 : 0.5844155844155844\n",
      "\n",
      "Decision Tree untuk X1 dan Y2 : 0.7662337662337663\n",
      "Decision Tree untuk X2 dan Y2 : 0.8311688311688312\n",
      "Decision Tree untuk X3 dan Y2 : 0.8311688311688312\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier_dt = DecisionTreeClassifier()\n",
    "\n",
    "classifier_dt.fit(X_train1, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_dt.fit(X_train1, y_train1)\n",
    "scores = cross_val_score(classifier_dt, X_train1, y_train1, cv=5)\n",
    "print(\"Confidence untuk X1 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_dt.score(X_test1, y_test1)\n",
    "\n",
    "print(\"Decision Tree untuk X1 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_dt.fit(X_train2, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_dt.fit(X_train2, y_train1)\n",
    "scores = cross_val_score(classifier_dt, X_train2, y_train1, cv=5)\n",
    "print(\"Confidence untuk X2 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_dt.score(X_test2, y_test1)\n",
    "\n",
    "print(\"Decision Tree untuk X2 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_dt.fit(X_train3, y_train1)\n",
    "\n",
    "# Cross Validation\n",
    "classifier_dt.fit(X_train3, y_train1)\n",
    "scores = cross_val_score(classifier_dt, X_train3, y_train1, cv=5)\n",
    "print(\"Confidence untuk X3 dan Y1:\", scores.mean())\n",
    "\n",
    "score = classifier_dt.score(X_test3, y_test1)\n",
    "\n",
    "print(\"Decision Tree untuk X3 dan Y1 :\", score)\n",
    "print()\n",
    "\n",
    "classifier_dt.fit(X_train1, y_train2)\n",
    "score = classifier_dt.score(X_test1, y_test2)\n",
    "\n",
    "print(\"Decision Tree untuk X1 dan Y2 :\", score)\n",
    "\n",
    "classifier_dt.fit(X_train2, y_train2)\n",
    "score = classifier_dt.score(X_test2, y_test2)\n",
    "\n",
    "print(\"Decision Tree untuk X2 dan Y2 :\", score)\n",
    "\n",
    "classifier_dt.fit(X_train3, y_train2)\n",
    "score = classifier_dt.score(X_test3, y_test2)\n",
    "\n",
    "print(\"Decision Tree untuk X3 dan Y2 :\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamter Tuning\n",
    "\n",
    "Hal ini untuk memaksimalkan nilai klasifikasi untuk model dengan log regression dan multinomial naive bayes, dengan fitur x yang sudah di stemming dan label daftar fakultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual=[True,False]\n",
    "max_iter=[50,100,110,120,130,140,150]\n",
    "solver=['liblinear']\n",
    "param_grid = dict(dual=dual,max_iter=max_iter, solver=solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.818182 using {'dual': True, 'max_iter': 50, 'solver': 'liblinear'}\n",
      "Execution time: 7.903137445449829 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator=classifier_log, param_grid=param_grid, cv = 5, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "grid_result = grid.fit(X_train2, y_train1)\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Accuracy for Log Regression :  0.8831168831168831\n"
     ]
    }
   ],
   "source": [
    "new_clf_log = LogisticRegression(dual= True, max_iter= 50,solver='liblinear',multi_class='ovr')\n",
    "new_clf_log.fit(X_train2, y_train1)\n",
    "score = new_clf_log.score(X_test2, y_test1)\n",
    "print(\"New Accuracy for Log Regression : \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.818182 using {'solver': 'liblinear', 'max_iter': 100, 'dual': True}\n",
      "Execution time: 2.326324701309204 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random = RandomizedSearchCV(estimator=classifier_log, param_distributions=param_grid, cv = 5, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "random_result = random.fit(X_train2, y_train1)\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Accuracy for Log Regression :  0.8831168831168831\n"
     ]
    }
   ],
   "source": [
    "new_clf_log = LogisticRegression(dual= True, max_iter= 140)\n",
    "new_clf_log.fit(X_train2, y_train1)\n",
    "score = new_clf_log.score(X_test2, y_test1)\n",
    "print(\"New Accuracy for Log Regression : \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
